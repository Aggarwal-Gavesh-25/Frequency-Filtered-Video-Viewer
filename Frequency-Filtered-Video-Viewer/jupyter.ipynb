{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The necessary libraries are imported. cv2 is OpenCV, for computer vision tasks. numpy is imported as np, which is used for numerical operations. signal module from scipy is imported as sig, which is used for signal processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import signal as sig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, filter_frequency, takes in a signal, a frequency range, and the frames per second (fps) of the video. It calculates the Nyquist frequency (half of the sampling rate), determines the cutoff frequency within the specified frequency range, designs a Butterworth low-pass filter with a 4th order, and filters the signal using scipy's filtfilt function, which applies a digital filter forward and backward to eliminate phase shifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_frequency(signal_data, freq_range, fps):\n",
    "    nyquist_freq = fps / 2\n",
    "    cutoff_freq = freq_range[1] / nyquist_freq\n",
    "    b, a = sig.butter(4, cutoff_freq, 'low', analog=False)\n",
    "    filtered_signal = sig.filtfilt(b, a, signal_data)\n",
    "    return filtered_signal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A video file is opened for reading using cv2.VideoCapture(), and the frames per second (fps) of the video are obtained using cap.get(cv2.CAP_PROP_FPS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('/Users/gavesh_aggarwal/Desktop/Frequency-Filtered-Video-Viewer/video.mp4')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-3 :- This while loop iterates over each frame of the video. cap.read() reads the next frame from the video, and ret is a boolean value indicating whether the frame was successfully read.\n",
    "\n",
    "4-8 :- Here, an array filtered_frame is created to store the filtered image. The loop iterates over each color channel (assuming BGR), flattens the channel to 1D, filters the frequency components using the filter_frequency function, reshapes the filtered channel back to the original shape, and assigns it to filtered_frame.\n",
    "\n",
    "9-10 :- The filtered image is normalized to the 0-255 range and converted to the uint8 data type, which is expected by cv2.imshow().\n",
    "\n",
    "11-12 :- Both the original and filtered frames are displayed using cv2.imshow().\n",
    "\n",
    "13-14 :- This line waits for a key press for 25 milliseconds. If the pressed key is 'q', the loop breaks, and the program ends.\n",
    "\n",
    "15-16 :- If ret is False, indicating that there are no more frames to read, the loop breaks, and the program ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 23:18:00.765 Python[79850:4433836] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "while(cap.isOpened()):                                                                      # 1\n",
    "    ret, frame = cap.read()                                                                 # 2\n",
    "    if ret == True:                                                                         # 3\n",
    "\n",
    "        filtered_frame = np.zeros_like(frame)                                               # 4\n",
    "        for i in range(3):                                                                  # 5\n",
    "            filtered_channel = filter_frequency(frame[:,:,i].flatten(), (0, 1), fps)        # 6\n",
    "            filtered_channel = filtered_channel.reshape(frame[:,:,i].shape)                 # 7\n",
    "            filtered_frame[:,:,i] = filtered_channel                                        # 8\n",
    "\n",
    "        filtered_frame = cv2.normalize(filtered_frame, None, 0, 255, cv2.NORM_MINMAX)       # 9\n",
    "        filtered_frame = np.uint8(filtered_frame)                                           # 10\n",
    "\n",
    "        cv2.imshow('Original', frame)                                                       # 11\n",
    "        cv2.imshow('Filtered (0-1 Hz)', filtered_frame)                                     # 12\n",
    "\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):                                              # 13\n",
    "            break                                                                           # 14\n",
    "        \n",
    "    else:                                                                                   # 15\n",
    "        break                                                                               # 16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, cap.release() releases the video capture object, and cv2.destroyAllWindows() closes all OpenCV windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
